{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bffbb0c",
   "metadata": {},
   "source": [
    "# Test Dataset to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c466d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "NUM_PROCESSORS=multiprocessing.cpu_count()\n",
    "# print(\"Cpu count: \",NUM_PROCESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b785488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as it turned out interactive shell (like Jupyter cannot handle CPU multiprocessing well so check which medium the code is runing)\n",
    "#we will write code in Jupyter for understanding purposes but final execuation will be in shell\n",
    "from ipynb.fs.full.Utils import isnotebook\n",
    "from ipynb.fs.full.Dataset import get_data\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "import torch_geometric.utils.homophily as homophily\n",
    "import copy\n",
    "import ipynb.fs.full.utils.MoonGraph as MoonGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e61e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_sparse import SparseTensor\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "import random\n",
    "from random import choice\n",
    "random.seed(12345)\n",
    "import numpy as np\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0d46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from multiprocessing.pool import ThreadPool, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c58f589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data, dataset = get_data('Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1740858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import identity\n",
    "from scipy.sparse import csgraph\n",
    "from scipy import linalg\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy import sparse, stats\n",
    "#from scipy.sparse import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5466d5",
   "metadata": {},
   "source": [
    "## Effective Resistance (True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee687ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ER(u,v, L_inv,N):\n",
    "    \n",
    "    x_u = np.zeros((N,))\n",
    "    x_v = np.zeros((N,)) \n",
    "    x_u[u] = 1\n",
    "    x_v[v] = 1\n",
    "    \n",
    "    d_uv=x_u-x_v\n",
    "    \n",
    "    R_uv=d_uv.dot(L_inv.dot(d_uv)) ## (x_u-x_v)^T*L'*(x_u-x_v)\n",
    "    \n",
    "    return R_uv\n",
    "\n",
    "def compute_ER(Adj, L_inv):\n",
    "\n",
    "    start_nodes, end_nodes, weights = sparse.find(sparse.tril(Adj))\n",
    "    n = np.shape(Adj)[0]\n",
    "    Reff = sparse.lil_matrix((n,n))\n",
    "    \n",
    "    for orig, end in zip(start_nodes, end_nodes):\n",
    "        Reff[orig,end] = ER(orig, end, L_inv, n)\n",
    "        \n",
    "    return Reff\n",
    "\n",
    "def EffectiveResistance(data):\n",
    "    \n",
    "    N = data.num_nodes\n",
    "    E = data.num_edges\n",
    "    \n",
    "    Adj = coo_matrix(([1] * E, (data.edge_index[0], data.edge_index[1])), shape=(N,N))    \n",
    "\n",
    "    #Adj = nx.adjacency_matrix(G)\n",
    "    L, D  = csgraph.laplacian(Adj, normed=False, return_diag=True)\n",
    "    \n",
    "    #print(np.allclose(L.todense(), np.diag(D)-Adj)) #verify L=D-A\n",
    "        \n",
    "    L_inv = linalg.pinv(L.todense())\n",
    "    \n",
    "    Reff=compute_ER(Adj, L_inv)\n",
    "    \n",
    "    return Reff    \n",
    "\n",
    "# Reff = EffectiveResistance(data)\n",
    "# Reff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3684fa",
   "metadata": {},
   "source": [
    "## Effective Resistance (Local Approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae7d866b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class EffectiveRessistance():\n",
    "    \n",
    "    def __init__(self, data, eps=0.9, lmbda=0.10):\n",
    "        \n",
    "        self.N = N = data.num_nodes\n",
    "        self.E = E = data.num_edges\n",
    "        self.data = data\n",
    "        self.eps = eps\n",
    "        self.lmbda = lmbda\n",
    "\n",
    "#         self.Adj = SparseTensor(\n",
    "#             row=data.edge_index[0], \n",
    "#             col=data.edge_index[1],\n",
    "#             value=torch.arange(E, device=data.edge_index.device),sparse_sizes=(N, N))\n",
    "        \n",
    "        if N == 232965:\n",
    "            G_fillename=\"reddit.gpickle\"\n",
    "            if os.path.exists(G_fillename)==False:\n",
    "                print(\"Graph is not found, creating it....\")\n",
    "                self.G = to_networkx(data, to_undirected=True)\n",
    "                nx.write_gpickle(self.G, G_fillename)\n",
    "                print(\"Done\")\n",
    "            else:\n",
    "                print(\"Loading Saved graph...\")\n",
    "                self.G = nx.read_gpickle(G_fillename)\n",
    "                print(\"Done\")\n",
    "    \n",
    "        else:\n",
    "            self.G = to_networkx(data, to_undirected=True)\n",
    "    \n",
    "    def random_walk(self, s, l):\n",
    "        v = s;\n",
    "        for i in range(l):  \n",
    "            if (len(self.G[v]) == 0):\n",
    "                continue;\n",
    "            v = choice(list(self.G.neighbors(v)))\n",
    "\n",
    "        return v\n",
    "\n",
    "\n",
    "    def er_edge(self, index, s, t, eps=0.1, lmbda=0.1):\n",
    "        \n",
    "#         l = math.ceil(math.log(4 / (eps * (1 - lmbda))) / math.log(1.0 / lmbda) / 2)\n",
    "#         r = int(math.ceil(40 * l * l * math.log(80 * l) / (eps * eps)))\n",
    "\n",
    "        l = 4\n",
    "        r = 100\n",
    "#         print(l,r)     \n",
    "        \n",
    "        delta = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        s_deg = self.G.degree[s]\n",
    "        t_deg = self.G.degree[t]\n",
    "        \n",
    "        #print(self.G.degree[s], self.G.degree[t])\n",
    "\n",
    "        for i in range(l):\n",
    "            Xis = 0; Xit = 0; Yis = 0; Yit = 0;\n",
    "\n",
    "            for j in range(r):\n",
    "                v = self.random_walk(s, i)\n",
    "                if (v == s):\n",
    "                    Xis+=1\n",
    "                if (v == t):\n",
    "                    Xit+=1    \n",
    "\n",
    "            for j in range(r):\n",
    "                v = self.random_walk(t, i);\n",
    "                if (v == s):\n",
    "                    Yis+=1;\n",
    "                if (v == t):\n",
    "                    Yit+=1;\n",
    "\n",
    "            deltai = float(Xis) / s_deg  - float(Xit) / t_deg - float(Yis) / s_deg + float(Yit) / t_deg\n",
    "            deltai /= r;\n",
    "            delta += deltai;\n",
    "\n",
    "        return index, max(0,delta)\n",
    "    \n",
    "    def er_weight(self):\n",
    "        \n",
    "        weight = np.zeros(len(self.data.edge_index[0]))\n",
    "        \n",
    "        pbar = tqdm(total=self.E)\n",
    "        pbar.set_description(f'Edges')\n",
    "        \n",
    "        for i, edge in enumerate(self.data.edge_index.T.tolist()):\n",
    "            _, weight[i] = self.er_edge(i, edge[0], edge[1], eps=self.eps, lmbda=self.lmbda)\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "        pbar.close()\n",
    "            \n",
    "        weight = torch.Tensor(weight)\n",
    "            \n",
    "        return weight\n",
    "    \n",
    "    \n",
    "    def block(self, edge_list):\n",
    "        \n",
    "        for (i, u, v) in edge_list:\n",
    "            _, self.weight[i] = self.er_edge(i, u, v, eps=self.eps, lmbda=self.lmbda)        \n",
    "        \n",
    "        return len(edge_list)\n",
    "    \n",
    "    def er_weight_parallel(self):\n",
    "        \n",
    "        pool_size = NUM_PROCESSORS        \n",
    "        #pool_size=1\n",
    "        print(\"Pool Size: \", pool_size)        \n",
    "        pool = Pool(pool_size)\n",
    "        \n",
    "        elem_size= 1000000\n",
    "        num_blocks = int(self.E/elem_size)\n",
    "                            \n",
    "        self.weight = np.zeros(len(data.edge_index[0]))\n",
    "        u =  self.data.edge_index[0].tolist()\n",
    "        v =  self.data.edge_index[1].tolist()\n",
    "        \n",
    "        param = list(zip(range(self.E), u, v))\n",
    "        params = [ param[i*elem_size:(i+1)*elem_size] for i in range(num_blocks)]\n",
    "        \n",
    "        if num_blocks*elem_size<self.E:\n",
    "            params.append(param[num_blocks*elem_size:self.E]) \n",
    "                          \n",
    "        #print(params)\n",
    "        \n",
    "        pbar = tqdm(total=self.E)\n",
    "        pbar.set_description(f'Edges') \n",
    "        \n",
    "        for num_el in pool.imap_unordered(self.block, params):            \n",
    "            pbar.update(num_el)        \n",
    "        pbar.close()\n",
    "                \n",
    "        return self.weight\n",
    "\n",
    "    def compute_weights(self):\n",
    "        if isnotebook():\n",
    "            weight = self.er_weight()    \n",
    "        else:\n",
    "            weight = self.er_weight_parallel()\n",
    "        \n",
    "        return weight\n",
    "    \n",
    "# er = EffectiveRessistance(data, eps=0.1, lmbda=0.1)\n",
    "# er.er_edge(0, 20, 21)\n",
    "#er.er_weight()\n",
    "# #er.er_weight_parallel()\n",
    "#weight  = er.compute_weights()\n",
    "# torch.save(weight, 'Weights/reddit_er.pt')\n",
    "# torch.load('Weights/reddit_er.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a5728bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineNNandER(data, metric='cosine'):\n",
    "    \n",
    "    from ipynb.fs.full.KNNWeights import KNNWeight\n",
    "    \n",
    "    NN = KNNWeight(data, metric=metric)\n",
    "    ER = EffectiveRessistance(data, eps=0.9, lmbda=0.10)\n",
    "    \n",
    "    nn_weight = NN.compute_weights()\n",
    "    er_weight = ER.er_weight()\n",
    "    \n",
    "    return nn_weight*er_weight\n",
    "\n",
    "#CombineNNandER(data, metric='cosine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddbb922",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec49c506",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory:  /scratch/gilbreth/das90/Dataset/\n",
      "Result directory: /scratch/gilbreth/das90/Dataset/RESULTS/\n",
      "\n",
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "===========================================================================================================\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Training node label rate: 0.05\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "Node Homophily: 0.825157880783081\n",
      "Edge Homophily: 0.8099659085273743\n",
      "Edge_insensitive Homophily: 0.7657181620597839\n",
      "Assortativity:  -0.06587088108062744\n",
      "Metric:  cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nodes: 100%|██████████| 2708/2708 [00:01<00:00, 2591.41it/s]\n",
      "Edges: 100%|██████████| 10556/10556 [00:16<00:00, 649.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  17.452056884765625\n",
      "Node Homophily: 0.3830185830593109\n",
      "Edge Homophily: 0.8399452567100525\n",
      "Edge_insensitive Homophily: 0.7945449948310852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':  \n",
    "    \n",
    "    data, dataset = get_data('Cora')\n",
    "    \n",
    "#     print(\"Node Homophily:\", homophily(data.edge_index, data.y, method='node'))\n",
    "#     print(\"Edge Homophily:\", homophily(data.edge_index, data.y, method='edge'))\n",
    "#     print(\"Edge_insensitive Homophily:\", homophily(data.edge_index, data.y, method='edge_insensitive'))    \n",
    "    \n",
    "#     er = EffectiveRessistance(data)\n",
    "\n",
    "    start = time.time()    \n",
    "    #data.weight  = er.er_weight(eps=0.9, lmbda=0.1)\n",
    "    data.weight = CombineNNandER(data, metric='cosine')\n",
    "    end = time.time()\n",
    "    print(\"Execution time: \", end-start)\n",
    "\n",
    "    if 'weight' in data:\n",
    "        cp_data= copy.deepcopy(data)\n",
    "        G = to_networkx(cp_data, to_undirected=True, edge_attrs=['weight'])\n",
    "        to_remove = [(a,b) for a, b, attrs in G.edges(data=True) if attrs[\"weight\"] <0.5 ]\n",
    "        G.remove_edges_from(to_remove)\n",
    "        updated_data = from_networkx(G)\n",
    "\n",
    "        print(\"Node Homophily:\", homophily(updated_data.edge_index, cp_data.y, method='node'))\n",
    "        print(\"Edge Homophily:\", homophily(updated_data.edge_index, cp_data.y, method='edge'))\n",
    "        print(\"Edge_insensitive Homophily:\", homophily(updated_data.edge_index, cp_data.y, method='edge_insensitive'))    \n",
    "        \n",
    "    \n",
    "    None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38cu11",
   "language": "python",
   "name": "py38cu11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
